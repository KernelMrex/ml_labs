{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Устанавливаем зависимости",
   "id": "d174b67356597612"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!python --version",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install sktime==0.37.0 pytorch-forecasting==1.3.0 pytorch-lightning==2.1.3",
   "id": "c8a54550e1af75d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Подготавливаем данные",
   "id": "4f2c04604d924945"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Подготоваливаем данные в df",
   "id": "21c789f271d72489"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "fe6e9f44a0beb12d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/SANDUSDT.csv', sep=',', decimal='.', index_col='datetime', parse_dates=['datetime'])\n",
    "df.head()"
   ],
   "id": "e35a2a3852e278a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Копируем df чтобы избежать ошибок изменения",
   "id": "ade54830879a743e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.copy()",
   "id": "e46dee7d3ed18a1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверяем типы",
   "id": "9997bbbd51dc5d5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.dtypes)",
   "id": "4e07776d22d65383",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Изучаем полученные данные",
   "id": "405d588fe11584a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe()",
   "id": "47de728b112d87ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Визуализируем входные данные",
   "id": "9e1ebdde66621c61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install plotly",
   "id": "263ef454a95c6148",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "vdf = df.copy()\n",
    "\n",
    "vdf['Close'] = vdf[\"Open\"] + vdf[\"open_close_delta\"]\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(\n",
    "    #x=vdf[\"datetime\"],\n",
    "    x=vdf.index,\n",
    "    open=vdf[\"Open\"],\n",
    "    high=vdf[\"High\"],\n",
    "    low=vdf[\"Low\"],\n",
    "    close=vdf[\"Close\"],\n",
    "    increasing_line_color='green',\n",
    "    decreasing_line_color='red'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"OHLC график по торговым данным\",\n",
    "    xaxis_title=\"Время\",\n",
    "    yaxis_title=\"Цена\",\n",
    "    xaxis_rangeslider_visible=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "bcb08093db964cf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Полученные данные неравномерные. Заполняем промежуточные данные",
   "id": "bc584213735304e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()\n",
    "df = df.resample('1min').asfreq()\n",
    "#df = df.infer_objects(copy=False)\n",
    "\n",
    "# Интерполируем только числовые колонки\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "df[numeric_cols] = df[numeric_cols].interpolate(method=\"linear\")"
   ],
   "id": "4612ff6d46fdd0c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверяем есть ли пустые данные",
   "id": "a8047bcfd22928b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.isna().sum()",
   "id": "befd570875e885ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df[:1200]",
   "id": "8b81fb0892f5c750",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Разделяем на тестовые данные и контрольные",
   "id": "b5c2436f02f0c427"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Целевая переменная\n",
    "y = df[\"High\"].astype(np.float32)\n",
    "\n",
    "# Остальные признаки: Неправильно, т.к. нам недоступен объем торгов и т.д.(Это надо будет упомянуть в презентации, это называется \"data leakage\")\n",
    "# X = df.drop(columns=[\"High\"])\n",
    "\n",
    "# Правильный вариант\n",
    "X = df[[\"sin_hour\", \"cos_hour\", \"sin_day_of_week\", \"cos_day_of_week\"]] # datetime тут не упоминаем, потому что это индекс"
   ],
   "id": "f231a9d81cd2d341",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sktime.split import temporal_train_test_split\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "\n",
    "# Последние N шагов — на тест\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X, test_size=48)\n",
    "\n",
    "# Горизонт предсказания\n",
    "fh = ForecastingHorizon(y_test.index, is_relative=False)"
   ],
   "id": "50f703888760d68e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверяем валидность данных",
   "id": "9740b62d0948943e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_train.isna().sum(), X_train.isna().sum()",
   "id": "b2e761d7655d76e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Конфигурируем пайплайн",
   "id": "5178061e0909aa3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Пишем адаптер для DeepAR\n",
    "\n",
    "Т.к. напрямую использование `PytorchForecastingDeepAR` в пайплайне невозможно(видимо баг, хз), нужно написать адаптер который будет расширять шаблонный класс BaseForecaster.\n",
    "\n",
    "Похожий PR: https://github.com/sktime/sktime/pull/7447"
   ],
   "id": "69c18c96d9cb7259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sktime.forecasting.base import BaseForecaster\n",
    "from sktime.utils.validation.series import check_series\n",
    "\n",
    "\n",
    "class DeepARAdapter(BaseForecaster):\n",
    "    def __init__(self, deep_ar_forecaster):\n",
    "        self.deep_ar_forecaster = deep_ar_forecaster\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, y, X=None, fh=None):\n",
    "        y = check_series(y)  # Проверить входные данные\n",
    "        self._set_fh(fh)  # Установить (или проверить) горизонт прогноза\n",
    "        self.deep_ar_forecaster.fit(y, X, fh=self._fh)  # Обучение модели DeepAR\n",
    "        return self\n",
    "\n",
    "    def predict(self, fh=None, X=None):\n",
    "        self.check_is_fitted()  # Проверка, была ли модель обучена\n",
    "        fh = self._check_fh(fh)  # Проверка горизонта прогноза\n",
    "        res = self.deep_ar_forecaster.predict(fh, X)  # Получить прогноз\n",
    "\n",
    "        print(res)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def _set_fh(self, fh):\n",
    "        self._fh = self._check_fh(fh)\n",
    "\n",
    "    def is_fitted(self):\n",
    "        return True"
   ],
   "id": "9af13a2302572480",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### (Опционально) Пишем свой SoftplusScaler\n",
    "Сделал чтобы прверить что такое вообще возможно. Вроде как дружит с TorchNormalizer-ом"
   ],
   "id": "b28c613b43dcc6f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class SoftplusScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, epsilon=1e-6):  # теперь epsilon — параметр конструктора\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = self._to_numpy(X)\n",
    "        self.min_ = X.min()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self._to_numpy(X)\n",
    "        return np.log1p(np.exp(X))  # softplus\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        X = self._to_numpy(X)\n",
    "        return np.log(np.expm1(X) + self.epsilon)  # inverse softplus\n",
    "\n",
    "    def _to_numpy(self, X):\n",
    "        if isinstance(X, torch.Tensor):\n",
    "            return X.detach().cpu().numpy()\n",
    "        elif hasattr(X, \"to_numpy\"):\n",
    "            return X.to_numpy()\n",
    "        return X\n"
   ],
   "id": "b038935b80574459",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ### Пишем кастомный LagFeatureTransformer для X",
   "id": "8e708cf46411eb58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class LagFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns, lags):\n",
    "        self.columns = columns\n",
    "        self.lags = lags\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            for lag in self.lags:\n",
    "                X[f\"{col}_lag{lag}\"] = X[col].shift(lag)\n",
    "        return X\n"
   ],
   "id": "23629758b2ef03be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Создаем пайплайн\n",
    "\n",
    "НО!: на маке не работает нормально если использовать ускоритель(trainer_params.accelerator)=auto.\n",
    "Причина:\n",
    "> Это известная проблема при обучении PyTorch на MPS (Apple Silicon GPU). Дело не в данных и не в гиперпараметрах модели, а именно в реализации вычислений на GPU с MPS.\n",
    "> MPS (device='mps:0') пока ещё нестабилен в PyTorch и часто генерирует NaN при вычислениях градиентов и некоторых операций, особенно для сложных моделей (RNN, GRU, LSTM, DeepAR).\n",
    "Это вызвано тем, что поддержка MPS в PyTorch официально пока не завершена и не до конца стабилизирована."
   ],
   "id": "bb28faf5e06c8153"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.forecasting.pytorchforecasting import PytorchForecastingDeepAR\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer\n",
    "\n",
    "# Mac: Apple Silicon\n",
    "platform_dependant_params = {\n",
    "    \"accelerator\": \"cpu\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "}\n",
    "\n",
    "# # Other\n",
    "# platform_dependant_params = {\n",
    "#     \"accelerator\": \"auto\",\n",
    "#     \"learning_rate\": 1e-5,\n",
    "# }\n",
    "\n",
    "trainer_params = {\n",
    "    \"max_epochs\": 20,\n",
    "    \"gradient_clip_val\": 0.1,\n",
    "    \"accelerator\": platform_dependant_params[\"accelerator\"],\n",
    "    \"enable_model_summary\": True,\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    \"cell_type\": \"GRU\",\n",
    "    \"hidden_size\": 64,  # (опционально) размер GRU\n",
    "    \"dropout\": 0.1,  # (опционально)\n",
    "    \"rnn_layers\": 2,  # (опционально)\n",
    "    #\"loss\": NormalDistributionLoss(),\n",
    "    \"output_transformer\": TorchNormalizer(transformation=\"softplus\"),\n",
    "    \"learning_rate\": platform_dependant_params[\"learning_rate\"],\n",
    "}\n",
    "\n",
    "deep_ar_forecaster = PytorchForecastingDeepAR(\n",
    "    trainer_params=trainer_params,\n",
    "    model_params=model_params,\n",
    ")\n",
    "\n",
    "pipe_deepar = TransformedTargetForecaster(steps=[\n",
    "    # Преобразование временного ряда y с помощью StandardScaler\n",
    "    #(\"scaler\", TabularToSeriesAdaptor(StandardScaler())), # либо TorchNormalizer(сразу два нельзя)\n",
    "\n",
    "    # Генерация лагов по X. Лаги нужны чтобы учитывались Volume, Open, Low из прошлых значений\n",
    "    # (\"lagger\", TabularToSeriesAdaptor(LagFeatureTransformer(columns=[\"Volume\", \"Open\", \"Low\"], lags=[1,2]))),\n",
    "\n",
    "    # Softplus скейлер\n",
    "    (\"scaler\", TabularToSeriesAdaptor(SoftplusScaler())),\n",
    "\n",
    "    # Прогнозирование\n",
    "    (\"forecast\", DeepARAdapter(deep_ar_forecaster))\n",
    "])"
   ],
   "id": "6ab876a9835b25f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Обучаем модель\n",
    "**Важно**: DeepAR ожидает на вход только положительные значения, так что нужно поизвращаться с подготовкой значений для входа"
   ],
   "id": "fd3b7dc0cab0da6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pipe_deepar.fit(y_train, X=X_train, fh=fh)",
   "id": "61997c180d424876",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Получаем прогноз от модели",
   "id": "c53d4d7267858341"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Прогнозирование с автоматическим обратным преобразованием\n",
    "y_pred = pipe_deepar.predict(fh=fh, X=X_test)\n",
    "\n",
    "scaler = pipe_deepar.named_steps[\"scaler\"].transformer_  # SoftplusScaler\n",
    "\n",
    "# 1. Получаем объект scaler из пайплайна\n",
    "scaler = pipe_deepar.named_steps[\"scaler\"].transformer_\n",
    "\n",
    "# 2. Применяем обратное преобразование к прогнозу\n",
    "y_pred_raw = scaler.inverse_transform(y_pred.to_frame()).squeeze()\n",
    "\n",
    "# 3. Создаем Series с правильными индексами\n",
    "y_pred_descaled = pd.Series(y_pred_raw, index=y_pred.index, name=y_pred.name)\n",
    "\n",
    "# Визуализация с исходным масштабом\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(y.index, y.values, label='Исходные данные', alpha=0.5)\n",
    "plt.plot(y_train.index, y_train.values, label='Тренировочные данные', color='blue')\n",
    "plt.plot(y_pred_descaled.index, y_pred_descaled.values,\n",
    "         label='Прогноз (исходный масштаб)',\n",
    "         color='red',\n",
    "         linestyle='--')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "2a2129abf829147a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
